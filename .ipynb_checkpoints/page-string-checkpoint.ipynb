{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_path = \"/Users/damoncrockett/Dropbox/cogs220/proposal/lit/text/\"\n",
    "snippets = []\n",
    "for input_file in glob.glob(os.path.join(input_path,\"*.txt\")):\n",
    "    with open(input_file, \"r\") as input_file:\n",
    "        page_string = input_file.read().replace(\"\\n\",'').decode('ascii','ignore').encode('ascii')\n",
    "        #page_string = page_string[:1000]\n",
    "        snippets.append(page_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(snippets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pd.Series(snippets),columns=['txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data sonification: Do You See What I Hear? Uni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multisensory Data Sensualization Based on Huma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>~ n v i r o n ~ ~ n ~  for Visualization and S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Evaluating  the  Importance  of  Multi-sensory...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G  ModelGAIPOS-4184;  No.  of  Pages  9Gait  &amp;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 txt\n",
       "0  Data sonification: Do You See What I Hear? Uni...\n",
       "1  Multisensory Data Sensualization Based on Huma...\n",
       "2  ~ n v i r o n ~ ~ n ~  for Visualization and S...\n",
       "3  Evaluating  the  Importance  of  Multi-sensory...\n",
       "4  G  ModelGAIPOS-4184;  No.  of  Pages  9Gait  &..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>72IEEE TRANSACTIONS ON VISUALIZATION AND COMPU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Computers &amp; Graphics 24 (2000) 375}384Data Vis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Computers &amp; Graphics 34 (2010) 529536Contents ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Computers &amp; Graphics 35 (2011) 392401Contents ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Journal of Biomedical Informatics 37 (2004) 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>The VisualizationHandbook\f",
       "This page intention...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Hanoi,Vietnam,pp.\u0001\u0005\u0005{\u0001\u0006\u0002,May\u0001\\t\\t\b.Synergistic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Mller et al. BMC Bioinformatics 2014, 15(Suppl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>PROCEEDINGS of the HUMAN FACTORS and ERGONOMIC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Use of Natural Sounds and Metaphors forData Pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Data Visualizat ion Using Automat ic, Percept ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Glyph-Based Generic Network VisualizationRober...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Information Visualization (2006) 5, 260 -- 270...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Visualization and Data Analysis 2011, edited b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Visualization and Data Analysis 2014, edited b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Int. J. Human-Computer Studies (2002) 57, 2472...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Quality-Based Visualization MatricesGeorgia Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Vis Comput (2014) 30:13731393DOI 10.1007/s0037...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>EUROGRAPHICS 2013/ M. Sbert, L. Szirmay-KalosS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>DOI: 10.1111/j.1467-8659.2009.01429.xCOMPUTER ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>University of Nebraska - LincolnDigitalCommons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Information Visualization (2004) 3, 3648&amp; 2004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>ArticleGlyph sorting: Interactive visualizatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>DOI: 10.1111/j.1467-8659.2012.03118.xEurograph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>MUSE: A Musical Data Sonification ToolkitSures...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Using Shape to Visualize Multivariate Data Chr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Critical Design and Realization Aspectsof Glyp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Topics in Cognitive Science 3 (2011) 499535Cop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Subspace Search and Visualization to Make Sens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Reprinted with permission.(RR-81-26)Ann. Rev. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   txt\n",
       "6    72IEEE TRANSACTIONS ON VISUALIZATION AND COMPU...\n",
       "15   IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTE...\n",
       "26   Computers & Graphics 24 (2000) 375}384Data Vis...\n",
       "27   Computers & Graphics 34 (2010) 529536Contents ...\n",
       "28   Computers & Graphics 35 (2011) 392401Contents ...\n",
       "33   Journal of Biomedical Informatics 37 (2004) 38...\n",
       "40   \f",
       "The VisualizationHandbook\f",
       "This page intention...\n",
       "42   Hanoi,Vietnam,pp.\u0001\u0005\u0005{\u0001\u0006\u0002,May\u0001\\t\\t\b.Synergistic...\n",
       "49   Mller et al. BMC Bioinformatics 2014, 15(Suppl...\n",
       "50   PROCEEDINGS of the HUMAN FACTORS and ERGONOMIC...\n",
       "52   Use of Natural Sounds and Metaphors forData Pe...\n",
       "57   Data Visualizat ion Using Automat ic, Percept ...\n",
       "60   Glyph-Based Generic Network VisualizationRober...\n",
       "61   Information Visualization (2006) 5, 260 -- 270...\n",
       "67   Visualization and Data Analysis 2011, edited b...\n",
       "68   Visualization and Data Analysis 2014, edited b...\n",
       "70   Int. J. Human-Computer Studies (2002) 57, 2472...\n",
       "75   Quality-Based Visualization MatricesGeorgia Al...\n",
       "81   Vis Comput (2014) 30:13731393DOI 10.1007/s0037...\n",
       "92   EUROGRAPHICS 2013/ M. Sbert, L. Szirmay-KalosS...\n",
       "116  DOI: 10.1111/j.1467-8659.2009.01429.xCOMPUTER ...\n",
       "117  University of Nebraska - LincolnDigitalCommons...\n",
       "125  Information Visualization (2004) 3, 3648& 2004...\n",
       "126  ArticleGlyph sorting: Interactive visualizatio...\n",
       "134  DOI: 10.1111/j.1467-8659.2012.03118.xEurograph...\n",
       "137  MUSE: A Musical Data Sonification ToolkitSures...\n",
       "154  Using Shape to Visualize Multivariate Data Chr...\n",
       "157  Critical Design and Realization Aspectsof Glyp...\n",
       "203  Topics in Cognitive Science 3 (2011) 499535Cop...\n",
       "207  Subspace Search and Visualization to Make Sens...\n",
       "209  Reprinted with permission.(RR-81-26)Ann. Rev. ..."
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.txt.str.contains('glyph')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = df[df.txt.str.contains('glyph')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the Effectiveness and Efficiency of Visual Variables for Geographic Information Visualization Simone Garlandini and Sara Irina Fabrikant* Department of Geography, University of Zurich,  Wintherthurerstrasse 190, CH-8057 Zurich, Switzerland {simone.garlandini,sara.fabrikant}@geo.uzh.ch Abstract. We propose an empirical, perception-based evaluation approach for assessing the effectiveness and efficiency of longstanding cartographic design principles applied to 2D map displays. The approach includes bottom-up visual saliency  models  that  are  compared  with  eye-movement  data  collected  in  hu-man-subject  experiments  on  map  stimuli  embedded  in  the  so-called  flicker paradigm.  The  proposed  methods  are  applied  to  the  assessment  of  four  com-monly used visual variables for designing 2D maps: size, color value, color hue, and orientation. The empirical results suggest that the visual variable size is the most  efficient  (fastest)  and  most  effective  (accurate)  visual  variable  to  detect change under flicker conditions. The visual variable orientation proved to be the least  efficient  and  effective  of  the  tested  visual  variables.  These  empirical  re-sults  shed  new  light  on  the  implied  ranking  of  the  visual  variables  that  have been proposed over 40 years ago. With the presented approach we hope to pro-vide  cartographers,  GIScientists  and  visualization  designers  a  systematic  as-sessment method to develop effective and efficient geovisualization displays. Keywords: Geographic visualization, visual variables, eye movements, change blindness, empirical studies. 1   Introduction The  cartographic  design  process  is  about  a  systematic  transformation  of  collected (typically  multivariate)  spatial  data  into  a  two-,  three-  or  four-dimensional  visuo-spatial  display.  This  process  is  typically  performed  by  applying  scientific  (i.e.,  systematic,  transparent,  and  reproducible)  cartographic  design  methods,  as  well  as aesthetic expressivity. Principles and details of the map design process can be found in many of the well-established cartography textbooks (see for example Dent, 1999; Slocum  et  al.,  2008).  More recently,  cartographers  have  not  only  been  interested  in what looks good or what visually communicates well, but also increasingly how and why a particular design solution works well or not. Although the seemingly intuitive design principles have been successfully used for hundreds  of  years,  and  some  of  them  (e.g.,  light  is  lessdark  is  more)  have  even                                                            * Corresponding author. K. Stewart Hornsby et al. (Eds.): COSIT 2009, LNCS 5756, pp. 195211, 2009.  Springer-Verlag Berlin Heidelberg 2009 \f",
      "196 S. Garlandini and S.I. Fabrikant been internationally accepted as conventions, for example, in the statistics community (Palsky, 1999), very few of the proposed conventions have actually been tested sys-tematically for their effectiveness and efficiency with human users. One such example is  the  well-known  system  of  the  seven  visual  variables  proposed  initially  by  the French cartographer Jacques Bertin (1967; and translated to English in 1983) and later extended  by  various  cartographers,  see  for  example,  Morrison  (1974)  and MacEachren (1995). More recently, Bertins work has also received attention in the information  visualization  literature  (Mackinlay,  1989).  The  variables  seem  to  work when employed logically, but designers are typically not certain why. Unfortunately, there  is  very  little  empirical  evidence  on  the  effectiveness  and  efficiency  of  these visual variables (MacEachren, 1995). How can GIScientists, geovisualizers, and car-tographers be sure that their design decisions produce effective and efficient displays? Nave  users  tend  to  extract  information  based  on  perceptual  salience  rather  than  on thematic relevance (Lowe, 2003; Fabrikant & Goldsberry, 2005). For this reason, an empirical evaluation of design principles, and a systematic look into the relationships between perceptual salience and thematic relevance in visualization design is needed (MacEachren & Kraak, 2001) to understand how and why certain displays are more successful for spatial inference and decision making than others. 2   Related Work 2.1   Visual Variables for Guiding Visual Attention Bertin (1967/83) proposed a systematical approach to communicating information by visual means. He lists seven basic visual variables and presents effects of varying the perceptual properties of the visual variables in order to derive meaningful representa-tions. There are two planar variables (the x and y position on the map plane), and five so-called  retinal ones (size, color value, color hue,  shape, and orientation),  which we (and perhaps vision researchers) would probably translate as pre-attentive (Ber-tin,  1967/83).  Although  Bertin  (1967/83)  lists  these  variables  individually,  effective map representations can of course include a combination of various visual variables (MacEachren, 1995). Bertin  distinguishes  selective,  associative,  ordered  and  quantitative  visual  vari-ables.  A  visual  variable  is  selective  (e.g.,  color  hue)  and  therefore  fundamental  for symbolization of data, if all symbols can be easily isolated (perceptually selected) to form a group of similar symbols based on this variable (e.g., where are the red signs compared to the green signs). Bertin contends that shape (for points, lines and areas) and  orientation  (only  when  applied  to  areas)  are  not  selective.  Conversely,  a  visual variable is called associative (e.g., shape) if it allows to perceptually group all catego-ries or instances of symbols based on that particular visual characteristic (signs of the same shape with different sizes vs. signs of different sizes with the same shape). Only the visual variables size and color value are said to have perceptual dissociative char-acteristics (Bertin, 1967/83). With dissociative visual variables (e.g., size) it is easier to detect visual variations among the signs themselves, than to visually form groups of similar symbols across other visual variables. Dissociative variables can be ordered or  quantitative. A visual  variable is defined  ordered if it is possible  to perceptually rank symbols based on one particular visually varying characteristic (e.g., lighter vs. \f",
      " Evaluating the Effectiveness and Efficiency of Visual Variables 197 darker shading). If it is possible to perceptually quantify the degree of variation of a visual symbol, the visual variable property is defined as quantitative (e.g., size). Ber-tin furthermore ranks visual variables in an explicit sequence: higher order variables (e.g., size) which possess a greater number of perceptual characteristics (i.e., quantita-tive, ordered, and dissociative), compared to lower order variables (e.g., orientation), that may only have associative characteristics (only for areas). Ironically, Bertin does not cite any perceptual or psychophysical work that would provide  empirical  evidence  to  his  design  guidelines.  In  fact,  his  seminal  volume  on the Semiology of Graphics (1967/83) does not include any reference to any previous or  related  work.  Bertins  contributions  can  be  understood  within  the  context  of  the work  by  Gestalt  psychologists  such  as,  Wertheimer  and  Koffka  in  the  1920s  (re-viewed by Gregory, 1987 and Goldstein, 1989) who posited that the arrangement of features in an image plane will influence the perceived thematic or group membership relations  of  elements  (i.e.,  figure/ground  separation).  Bertins  proposals  have  been somewhat  supported  by  later  experimental  evidence  for  classic  visual  search  tasks (e.g.,  pop-out  vs.  conjunctive  search)  proposed  by  Treisman  and  colleagues  (e.g., Treisman  &  Gelade,  1980).  In  a  meta  study  summarizing  several  decades  of  visual search and attention work in psychology and neuroscience, Wolfe & Horowitz (2004) list color (hue), size and orientation as undoubted variables to guide visual attention (for static displays), and color value (luminance) and shape as probable cases. Inter-estingly,  these  variables  are  not  congruent  with  the  ordering  that  Bertin  suggests. Most if not all of this empirical work, however, has been performed on highly con-trolled,  and  therefore  simple  graphic  displays,  typically  containing  only  simple  and isolated geometrical signs, thus not complex graphics such as commonly used maps, or other kinds of visualizations. Visual  search  strategies  in  a  geographic  context  have  been  studied  on  realistic looking scenes such as maps (Lloyd, 1997), aerial photographs (Lloyd et al., 2002), and on remotely sensed images (Swienty et al., 2007). Additional empirical evidence for the validity of the visual variable system in more complex cartographic displays have  been  provided  in  the  context  of  weather  maps  (Fabrikant  et  al.,  in  press),  the-matic map animations (Fabrikant & Goldsberry, 2005), or for depicting the distance-similarity metaphor in information spatializations (Fabrikant et al., 2004; Fabrikant et al.,  2006).  Visual  attention  guiding  variables  have  also  been  employed  for  the  con-struction of computational vision models, as will be discussed in the next section. 2.2   Computational (Bottom Up) Models of Visual Attention Itti  &  Koch  (2001)  present  a  computational  framework  to  model  visual  saliency, based on based on neurobiological concepts of visual attention (Itti et al., 1998). The aim of the various computational  models of visual attention is to model and predict visual  attention  based  on  psychophysical  and  neurophysiological  empirical  findings with  human  subjects  (Koch,  2004).  Visual  saliency  models  also  allow  investigating complex  and  dynamic  situations  like  animations,  and  changing  natural  scenes (Rosenholtz et al., 2007). Hence, they seem to be promising candidates for evaluating map displays as well.  \f",
      "198 S. Garlandini and S.I. Fabrikant Fig. 1. Stimulus with predicted first eye fixation based on its saliency map  The  Itti  model  is  a  neural-net  based,  neurobiologically  plausible  vision  model. The goal of the model is to identify the focus of attention of a visual system (mam-mal  or  robot)  based  on  the  where  (e.g.,  perceptually  salient  characteristics),  but not  the  what  (e.g.,  semantic  characteristics,  requiring  cognition).  In  this  model, three filters are applied to extract color hue, color value and orientation contrasts at several levels of image resolutions in a visual scene. Interestingly, these are three of Bertins  proposed  visual  variables.  Three  feature  maps  (one  for  each  filter)  are computed  based  on  center-surround  comparisons.  Feature  maps  are  additionally computed at several image resolutions and  integrated to form a single conspicuity map for each feature type. A non-linear normalization is applied to each conspicuity map to amplify peaks of contrasts relative to noise in the background. In the final stage feature maps are combined to produce a single saliency map (SM). The sali-ency model also predicts a sequence of locations (ranked saliency peaks in the SM) that  will  attract  a  viewers  gaze  in  a  scene  (Parkhurst  et  al.,  2002). The  predicted initial eye fixation (white circle) is shown Figure 1. Lighter areas in Figure 1 iden-tify image locations with higher saliency. It  is  important  to  emphasize  that  the  Itti  saliency  map  does  not  reveal  top-down components of visual attention. However, because we specifically employ a bottom-up approach within the flicker paradigm (see next section), and we are interested in evaluating  the  retinal  (e.g.,  pre-attentive)  characteristics  of  map  symbols,  we contend  this  not  to  be  a  limitation  for  our  study.  Moreover,  despite  these  limits,  saliency  map  models  appear  to  have  already  proven  to  be  useful  for  cartographic purposes (Fabrikant  & Goldsberry, 2005; Fabrikant et al., in press). We employ the visual attention model developed by Itti and colleagues (Itti et al., 1998) as a baseline to later compare human subject viewing behaviors collected with eye movement data. While visual variables are said to guide visual attention based on visual saliency, it is important to be aware of limitations or failures of the visual system, which we discuss in the next sections. \f",
      " Evaluating the Effectiveness and Efficiency of Visual Variables 199 2.3   Failures in Visual Attention Change blindness refers to a failure in the visual system in that observers often fail to detect even very salient and large changes in a scene when a blank field separates two alternating  images.  Change  blindness  is  defined  as  the  inability  to  notice  changes that occur in clear view of the observer, even when these changes are large and the observer  knows  they  will  occur (Rensink, 2005: 76). According to Rensink (2005) change blindness occurs in different situations and under various conditions, thus it is a  well-established phenomenon of human visual perception. Changes involving per-ceptually salient features are easier to detect than changes involving perceptually less salient  features  (Simons,  2000).  As  mentioned  earlier,  previous  work  has  already demonstrated that visual attention and visual perception are tightly related (see review by Wolfe & Horowitz, 2004).  Rensink  et  al.  (1997)  introduced  the  flicker  paradigm  in  order  to  investigate  the phenomenon of change blindness. In the  flicker paradigm  an  original  image  A  re-peatedly alternates with a modified image A, with brief blank fields placed between successive images (Rensink, 1997: 368).  Attention  is  characterized  by  bottom-up  (stimulus-driven)  and  top-down  (goal-driven)  attentional  control  (Wright  &  Ward,  2008).  The  bottom-up  component  of attention is modeled in the flicker paradigm asking observers to detect the change as quickly  as  possible  (Rensink,  2005).  As  a  consequence,  the  memory  impact  on  the experiment is reduced, but not completely inhibited (Rensink, 2005). The  dependent  variable  that  can  be  measured  under  flicker  conditions  is  the  re-sponse time (Rensink, 2005). An observer is asked to solve three kinds of tasks: 1) change detection (what?), 2) change localization (where?), and 3) change identifica-tion (how?) (Rensink, 2002). Experimental results report that the identification task is typically the most complex task to handle (Rensink, 2002). 3   Experiment In a controlled experiment we empirically investigated the relationships between the perceptual salience and thematic relevance in static 2D map displays. We employed a systematic bottom-up evaluation approach using the flicker paradigm (Rensink et al., 1997), in combination with the eye movement data collection method. In our experi-ment we focus specifically on those visual variables (i.e., size, color value, color hue and  orientation)  that  according  to  Wolfe  &  Horowitz  (2004)  have  been  proven  in psychophysical studies not only to guide visual attention, but are also used in a state-of-the-art visual saliency models (Itti et al., 1998). In order to test the efficiency and effectiveness of these visual variables with users we prepared thirty-two thematic 2D map stimuli varying the visual variables size, color value, color hue and orientation (within-subject independent variables), embedded in a flicker display. The experiment consisted in solving three kinds of tasks: change detec-tion, change localization, and change description. We hypothesize that the most efficient visual variable is detected faster in a flicker display than less efficient ones. Moreover, the more effective a visual variable, the more accurate participants responses will be in a flicker display, compared to a less effective visual variable. To investigate these two \f",
      "200 S. Garlandini and S.I. Fabrikant hypotheses,  the  dependent  variables  time  of  response  and  accuracy  of  response  are measured. In addition to the traditional success measures we additionally collect proce-dural  data  in  the  form  of  participants  eye  movements  when  solving  the  experiment tasks. In this way, we hope to not only identify  which visual variable works best, but also how. Finally, we derived saliency maps of the stimuli using a bottom-up computa-tional  model  of  visual  attention    (Itti  et  al.,  1998).  These  saliency  maps  provide  additional information about the saliency effects of the employed visual variables, and permit validation with the collected eye movement data. Participants: Twenty participants (9 females and 11 males), recruited from the Uni-versity of Zurich (UZH) and from the Swiss Federal Institute of Technology (ETH) Zurich, took voluntarily part in this study. They were not given any recompensation for participation. Participants were on average 29 years old, and no one indicated to be color-blind. Participants  were selected to represent a range of professional back-grounds, without any experience regarding the flicker paradigm and its implications. On average the participant pool has a low to average training in geographic informa-tion  science,  such  as  cartography,  geographical  information  systems,  including  the general familiarity with and usage of spatial data. Participants had a low or average level of training in computer science and related fields. Materials: Sixty-four 2D map stimuli were designed in AdobeIllustrator and embed-ded  in  thirty-two  flicker  animations  using  AdobeFlash,  according  to  the  guidelines proposed by Rensink et al. (1997). The animations were embedded in a web page that could  be  automatically  loaded  by  the  eye  tracker  management  software  during  the experiment. The flicker animations include four types of maps (i.e., eight flicker an-imations  for  each  type)  systematically  varying  the  visual  variables  color  hue,  color value, size, and orientation (within-subject independent variables). To keep the map design consistent across trials, the stimuli included graudate circles and choropleths, as  depicted  in  Figure  2  below.  For  the  size  stimuli,  circle  sizes  changed,  while  the uniform area fills in the choropleth map was held constant. For the other three vari-ables the area fills were affected by change, while the cirlces sizes were held constant. Fgure 2 shows a map stimulus used in the experiment.  Fig. 2. Sample map stimulus evaluated in the study (color hue)  \f",
      " Evaluating the Effectiveness and Efficiency of Visual Variables 201 The maps in the flicker animation depict a set of randomly selected Swiss munici-palities at a scale of 1:100,000. The geometry of the maps was systematically rotated in steps of forty-five degrees to assure that participants would not recognize the loca-tion,  and  therefore  are  able  to  focus  their  attention  entirely  on  the  change  detection tasks. Based on the data characteristics (shown in the legend), we selected the appro-priate  visual  variable  for  each  thematic  map  stimulus,  applying  Bertins  (1967/83) design guidelines. Only the map portion of the graphic stimulus exhibits change be-tween two consecutive displays. The change locations were also systematically varied so that areas in the center and various periphery locations in the map would change. Map title and legend never changed. An arbitrary map title was chosen by randomly selecting a county name in the U.S.A. (unknown to Swiss participants). The chosen name  does  not  match  the  shown  geometry.  The  legend  includes  a  map  scale  (i.e., randomly selected representative fraction), a map symbol key, and respective attribute information. The maps do not contain any other map elements, such as author infor-mation,  data  source,  or  copyright  sources.  We  reduced  the  design  to  a  necessary (ecologically valid) minimum, in order to minimize cognitive load, and thus not fur-ther distract participants from the change detection tasks.1 Setup: The experiment took place in a windowless office, specifically designed and used to run eye movement experiments. It was administered on a Dell Precision 390 Windows  workstation. The Tobii Studio software  was employed to display the  map stimuli and test questions on a 20-inch flat panel display, at 1024 by 768 pixels screen resolution.  A  standard  mouse  and  keyboard  were  used  for  input.  Participants  eye movements  were recorded using a Tobii X120 eye tracker, at 60 Hz resolution. We employed a fixation filter with radius of 50 pixels, and minimal fixation duration at 100ms  to  collect  participants  eye  movements.  Response  time  was  measured  as  the elapsed time in milliseconds between the trial display appearing on the screen and the participant  hitting  a  designated  key  on  the  keyboard  to  proceed  to  the  next  screen containing test questions. Procedure:  At  the  beginning  of  the  test  session  participants  were  welcomed  to  the eye-tracking  lab,  signed  a  consent  form,  and  filled  out  a  background  questionnaire. Participants  were then asked to sit comfortably in front of the experiment computer connected to the eye tracker. Information on the testing procedure was displayed on the screen. Participants first performed two change detection trials to get comfortable with  the  test  instrument,  without  having  their  eyes  tracked.  Following  the  practice trials participants eye  movements  were calibrated  with the eye tracker. Participants were again informed to sit comfortably, but as still as possible during the experiment, to  improve  calibration  accuracy  and  consequently  the  eye  tracking  accuracy  for  the experiment. For each flicker animation, participants were asked to hit the F10 key as soon as they  saw  a  change.  After  the  animation  stopped  and  the  stimulus  disappeared,  an answer  screen  appeared  displaying  a  black  and  white  reference  map  including  area labels. Participants  were asked to answer three questions. Firstly, if they had seen a                                                            1 Stimuli and experimental questions are available at: http://www.geo.uzh.ch/~sgarland/master/. \f",
      "202 S. Garlandini and S.I. Fabrikant visual change (detection task); secondly, where they had seen the change (localization task); and finally, to describe the change (identification task). Participants responded to  the  test  questions  orally  by  refering  to  area  labels  on  the  reference  map  and  the experiment leader recorded their answers using a digital  microphone, and by typing responses into a digital file. After answering the three questions, participants launched the  next  flicker  animation  by  hitting  the  F10  key.  If  participants  did  not  see  any change, the animation stopped automatically after 60 seconds. Participants were then asked  to  continue  to  the  next  trial  by  hitting  the  F10  key.  The  display  order  of  the stimuli was randomized to avoid any potential learning bias. After completing the on-screen experiment participants were debriefed, and thanked for participation. 4   Results Figure 3 shows participants response times (efficiency) for the change detection task on the four tested visual variables. On average, participants took more time to detect a change in a map display varying the visual variable orientation (M=1.94s, SD=1.08s) compared  to  the  other  tested  visual  variables.  The  variable  size  yielded  the  shortest response time (M=0.65s, SD=0.21s), followed by color hue (M=0.92s, SD=0.73s) and color value (M=1.00s, SD=0.33s). A  repeated  measures  ANOVA  (including  a  Bonferroni  correction)  reveals  a  sig-nificant  overall  effect  for  the  (within-subject)  visual  variables  factor,  F(25.805)  = .000, p < .05, indicating that there is a significant efficiency difference between the visual variables under study. Pairwise comparisons reveal that the variable orientation is  indeed  the  least  efficient  visual  variable  for  detecting  a  change.  For  maps containing this visual variable people take significantly longer to detect a change than for  all  other  maps.  Furthermore,  while  the  variable  size  is  the  fastest  of  all  tested visual  variables,  it  is  only  significantly  faster  than  orientation  and  color  value.  The speed  advantage  to  color  hue  is  not  significant.  There  are  no  significant  speed differences between color hue and color value.   Fig. 3. Response time values in seconds   \f",
      " Evaluating the Effectiveness and Efficiency of Visual Variables 203 Fig. 4. Mean time to first fixation  We additionally investigated the efficiency (detection speed) of the visual variables by examining participants eye movement behavior. For each stimulus, we delineated an  area  of  interest  (AOI)  where  a  change  occurs  in  the  map.  The  efficiency  metric time to first fixation (Goldberg & Kotval, 1999) can be employed to identify how long participants take to first fixate that particular AOI. This metric is negatively correlated with the potential degree of saliency of a region. High values of time to first fixation denote low degrees of saliency (Jacob & Karn, 2003).  Figure 4 depicts the average length (in seconds), until participants fixated the relevant AOI for the first time during a trial. Again, people are slowest to first fixate on orientation changes, compared to color hue, color value, or size changes (fastest). A repeated measures ANOVA reports a significant main effect for the four tested visual  variables,  F(6.623)  =  .004,  p  <  .05.  Size  is  significantly  faster  compared  to orientation,  but  there  are  no  significant  differences  between  size  and  color  hue  or color  value.  Orientation  is  significantly  slower  than  all  the  other  tested  variables, except  compared  to  color  hue.  Size  (fastest)  and  orientation  (slowest)  are  at  the extreme ends of the efficiency spectrum.  There are no clear winners between color hue and color value.  Fig. 5. Percentages of changes detected without looking explicitly at the change AOI  \f",
      "204 S. Garlandini and S.I. Fabrikant As Irwin (2004) notes, it is likely that the area of visual attention is larger than the location  to  where  the  fovea  is  pointing  during  a  fixation.  Evidence  for  this  can  be found  in  Figure  5.  This  Figure  shows  percentages  of  change  that  participants  were able to detect correctly, without even fixating in the respective AOI. It is notable, that in 68% of the orientation trials (thus more than just by guessing) participants detected change  without  even  fixating  the  respective  change  AOI. The  percentages  for  the other trials are: color value (52%), size (36%) and color hue (28%), respectively. To further look into the attention guiding potential or saliency of a visual variable we computed a ratio between the fixation duration within an AOI placed in the visual center of the map and the fixation duration within a change AOI. If this ratio pro-vides lower values, observers eyes were less attracted to the target AOI compared to staring into the center of the map. Higher ratio values might suggest that peoples gazes moved around the map more or were attracted more readily to other attention guiding regions of the display. Size and color value (both 1.59) have the highest ratio, compared  with  orientation  (1.29),  and  color  hue  (1.20).  This  measure  qualitatively confirms the results depicted in Figure 4. Size and color value seem to have attracted participants gazes more than color hue and orientation. We now turn to change localization. Regardless of the visual variable, people gen-erally performed very well on the change localization tasks. This might be due to the stimuli having relatively low complexity. The size changes were localized practically error free (99%), followed by color hue and color value (both M=.994 SD=.028), and finally orientation with the lowest score (M=.925, SD=.143).  A repeated measures ANOVA for the change localization task provides evidence that there are significant differences among the visual variables, F(7.589) = .002, p < .05. Analog to the efficiency outcome for the change detection task, the variable ori-entation  (least  accurate  localization)  differs  significantly  from  size  (most  accurate localization). No significant effects seem to exist between the other visual variables. Figure 6 above also shows the percentage of correctly described types of changes. There is little difference in peoples accuracy describing the change for size (99%), color  hue  (92%)  and  color  value  (97%)  displays.  However,  changes  in  orientation seemed to have been much harder for people to describe accurately (69%).   Tasksdetectionlocalizationdescription100806040200sizeorientationhuevalue Fig. 6. Percentages of correct change detection, localization and description Visual Variables\f",
      " Evaluating the Effectiveness and Efficiency of Visual Variables 205 According to a repeated measures ANOVA there seems to be a significant differ-ence in the change description accuracy across the visual variables, F(15.227) = .000, p  <  .05.  The  variable  orientation  differs  significantly  from  to  the  other  three  visual variables, yielding the least accurate results. Size scores are highest again, with 100% description accuracy; significantly better than color hue and orientation. Color value does not differ significantly from size and color hue.  4.1   Computational Saliency Evaluation We  additionally  evaluated  the  animated  flicker  displays  with  previously  mentioned Itti saliency maps, using specifically the saliency model for dynamic visual scenes. In addition to contrasts in color hue, color value and orientation (for static scenes), the dynamic  model  also  takes  movement  variables  into  consideration  to  compute  the resulting  saliency  map.  The  additional  dynamic  variables  considered  are:  change  in location (motion up/down/right/left) as well as flicker (i.e., appearance and disappear-ance at a location).  We compared the location of highest saliency computed by the model and its re-spective predicted eye fixation pattern with the actual change locations and our own collected  eye  movement  data.  The  region  of  the  change  is  indeed  predicted  by  the model to be the  most  salient  region in  the saliency  map. The  model seems to  work particularly well for the size displays. Comparing the predicted saliency maps of the map stimuli across the four tested variables, it is notable that the model yields a few highly concentrated areas of high saliency for the size stimuli, but less so for the other variables,  where salient areas are  more spread out and less crisp. On average, color hue  has  more  salient  locations  in  its  saliency  maps  than  the  other  tested  variables. Consequently, one would expect that observers would be attracted to a larger number of locations competing for saliency (e.g., distractors), which might make the detection (pop out) of a changing area more difficult. Based on this, one might further argue that the variable color hue  would  yield the  worst results in a change detection task. However, our empirical results do not support this hypothesis. Participants had greater difficulty and took significantly longer to detect a change in an orientation map than for the other  maps. Perhaps  orientation  maps do  not provide enough visual contrast between the enumeration areas. The linear pattern of the zone boundaries is harder to isolate,  due  to  the  linear  fill  pattern  within  the  zones.  The  individual  enumeration units  seem  to  form  larger  homogeneous  regions  with  little  figure-ground  contrast.  Henderson & Ferreira (2004) note that uniform regions are characterized by low fixa-tion counts and consequently they do not draw visual attention. On average, orienta-tion provided fewer fixation  counts in the  change AOI than the other three visual variables. As we used animated graphic stimuli for the assessment of the visual variables, we need to also consider the effectiveness and efficiency of the visual variables for ani-mated, or dynamic (e.g., interactive) visualizations.  The overall advantage of size and (to a lesser extent) color value in the change description task can perhaps be explained by the additional influence of the dynamic variables (also computed for the saliency map).  Figures  7-8  show  samples  of  overall  saliency  maps  for  the  four  tested  visual variables, overlaid on top of a map stimulus (upper left panel). The lighter the shade \f",
      "206 S. Garlandini and S.I. Fabrikant (spot  light)  the  higher  the  saliency.  The  white  circle  in  the  map  stimulus  is  the  predicted  first  gaze  point  (location  of  highest  saliency).  All  the  saliency  attributes contributing to the overall saliency map are placed to the right and below of the map stimulus  (panels  with  black  background).  Both  size  (Figure  7a)  and  color  value  (Figure 8b) yield areas of high saliency that are highly localized, compact, of small extent, and with crisp boundaries (especially for the size variable). This is perhaps due to  optimal  correlation  of  the  visual  variables  (hue,  value  and  orientation)  with  the dynamic ones such as, flicker (on/off) and motion (left, down, up, and right). The hue maps (Figure 8a) and orientation maps (Figure 7b), showing a much more dispersed pattern in their saliency maps, for both the static (visual) and dynamic variables, seem to be less effective at guiding peoples attention to the relevant areas of change.   Fig. 7. Saliency maps for the visual variable size Fig. 8. Saliency map for the visual variable orientation   \f",
      " Evaluating the Effectiveness and Efficiency of Visual Variables 207 Fig. 9. Saliency map for the visual variable color hue Fig. 10. Saliency map for the visual variable color value (a)  (b)    Fig. 11. Fixation concentrations across all participants for (a) orientation and (b) size \f",
      "208 S. Garlandini and S.I. Fabrikant We now contrast (predicted) model results with our collected eye movement data. Figure 9 depicts two sample stimuli with aggregated eye fixations of all our partici-pants. The lighter the display the higher the fixation concentration and magnitude. It is striking (but somewhat counter intuitive) that the model correctly predicts (as shown in Figure 7b), and confirmed by our empirical data (Figure 9), that the largest of the graduated circles in the size display is attended the least. Both the center of the map and the smallest symbols receive most attention in the size display. It seems that (center-surround) contrast changes (modeled explicitly  in the saliency  maps) are in-deed  attention  guiding.  The  smaller  circles  offer  more  contrast-changes  against  a homogeneous background than larger circles. Interestingly, only a small portion of the relevant change AOI (marked with a star symbol in Figure 9) was fixated in the orien-tation stimulus (compare  with Figure 7b). This  might be explained by the corner of the AOI being closest to the center of the map. Furthermore, if center-surround con-trasts  are  relevant,  then  the  concentration  of  stable  boundary  lines  converging  in  a corner offer perhaps more contrast opportunities compared to directional changes of a linear fill pattern. Overall, the model results and empirical result are very encouraging for cartogra-phers, because they suggest that commonly employed visual variables, when correctly applied,  are  indeed  able  to  effectively  and  efficiently  guide  observers  attention  to relevant information. As Lowe (2003) suggests, congruently displaying thematically relevant information in a perceptually salient manner is one of the key challenges for designing effective and efficient map displays. However, empirical results presented in Figures 5 and 9, also provide some evidence that foveal attention and saliency are not always located in the same location. 5   Discussion Summarizing our results we find that the selected four tested visual variables (Bertin, 1967/83)  are  indeed  attention  guiding,  as  people  performed  significantly  above chance  (e.g.,  50%)  in  detecting,  localizing  and  describing  a  change  in  the  display. This  is  in  accordance  to  the  summary  of  results  presented  in  Wolfe  &  Horowitz (2004)s meta study on attention guiding attributes. These authors list color, motion, orientation,  and  size  as  undoubted  attributes  to  guide  visual  attention.  However, unlike  Bertin  (1967/83),  Wolfe  &  Horowitz  (2004) do  not  provide  a  ranking  of  the attributes. Our empirical results do provide some evidence for the implied ordering of Bertins visual variables. We find the visual variable size to be the most efficient and effective variable to guide viewers attention in thematic 2D maps, under flicker con-ditions.    Perhaps  this  can  be  explained  by  the  size  displays  being  visually  the  least complex (e.g.,  having  fewer  visual distractors), according  to the computational sali-ency model shown in Figure 7. According to Bertin, size is the only visual variable that has quantitative, ordered, selective (the signs perceived as different), and dissaso-ciative characteristics (the signs are perceived as not similar). In fact, Bertin attributes size most dissassociativeness. Since size emphasizes sign difference (e.g., change), one might argue from an information theoretic encoding perspective that difference or change  could  be  an  aspect  of  interestingness,  and  thus,  a  very  useful  quality  to guide attention. Since early eye movement studies on visual displays (Buswell, 1935; \f",
      " Evaluating the Effectiveness and Efficiency of Visual Variables 209 Yarbus, 1967), it has been known that people concentrate their fixations on interest-ing and informative scene regions (Henderson & Ferreira, 2004). The visual variable orientation appeared to be least effective and efficient of the four  tested  visual  variables.  As  Bertin  (1983:  93)  writes:  in  area  representation variation in orientation is the easiest to construct, but it is at the same time the least selective [of all seven visual variables].  Bertin assigns orientation only one attention guiding characteristic (i.e., associativity). He argues that with orientation (in areas) it is harder to isolate an area of change, as the variable emphasizes similarity, thus has a more  uniform  or  homogeneous  appearance.  The  computed  saliency  maps  and  our collected gaze data seem to support this idea. For the color value and color hue variables the result pattern is not as clear. While color hue and color value yielded similar results, color value seems to have a slight (but non significant) advantage.  In Bertins system, color value differs from size only in the lack of a quantitative characteristic, thus one would have expected color value to perform better than hue for change detection. These results might support Wolfe & Horowitz  (2004)s  questioning  of  luminance  polarity  (e.g.,  contrast  in  brightness  or color  value)  as  an  attention-guiding  attribute.  They  suggest  it  might  be  a  subset  of color, that is, the luminance axis of a three-dimensional color space. 6   Conclusion This  paper  presents  a  systematic  empirical  evaluation  approach  to  assess  the  effec-tiveness  and  efficiency  of  four  commonly  employed  visual  variables  (size,  color value, color hue and orientation) for the design of 2D map displays (Bertin, 1967/83). The proposed evaluation approach combines the application of visual saliency models developed in research on human vision with the assessment of change under flicker conditions by combining traditional performance measures (accuracy and speed) with eye movement recordings. We find that the visual variable size performs most effec-tively (accurately) and most efficiently (fastest) under flicker conditions. Conversely, the visual variable orientation seems to be least effective and efficient in our change detection  experiment.  For  color  hue  and  color  value  the  results  pattern  are  not  as clear. Our results suggest validity to the implied ordering of the visual variables pro-posed  by  cartographer  Jacques  Bertin  (1967/83)  over  40  years  ago.  This  study  also shows  that  both  the  saliency  map  approach  and  the  measurement  of  eye  fixations under flicker conditions can be employed to systematically assess the utility of Ber-tins (1967/83) system of seven visual variables widely used in cartography, and also discovered in information visualization (Mackinlay, 1989). The visual variable system was developed specifically to help cartographers better control the visual salience of symbols  on  maps.    However,  until  today  it  lacked  in  systematical  validation  proce-dures, which we hope to have provided with this contribution.  Acknowledgments.  We  would  like  to  thank  our  participants  who  were  willing  to participate  in  our  research  and  are  grateful  for  Mary  Hegartys  continued  insightful feedback on all things related to the eye movement data collection method. We also thank  Alan  MacEachren  for  his  valuable  feedback  on  an  earlier  draft  of  this  manu-script. \f",
      "210 S. Garlandini and S.I. Fabrikant References Bertin, J.: Semiology of Graphics: Diagrams, Networks, Maps. University of Wisconsin Press, Madison (1983) (French edn., 1967) Buswell, G.T.: How People Look at Pictures. University of Chicago Press, Chicago (1935) Mackinlay, J.D.: Automating the Design of Graphical Presentations of Relational Information. ACM Transactions on Graphics 5(2), 110141 (1986) Dent, B.D.: Cartography. Thematic Map Design, Wm. C. Brown, Dubuque, IA (1999) Fabrikant, S.I., Goldsberry, K.: Thematic Relevance and Perceptual Salience of Dynamic Geo-visualization  Displays.  In:  Proceedings,  22th  ICA/ACI  International  Cartographic  Confer-ence, A Corua, Spain, July 9-16 (2005) Fabrikant,  S.I.,  Montello,  D.R.,  Ruocco,  M.,  Middleton,  R.S.:  The  Distance-Similarity  Meta-phor  in  Network-Display  Spatializations.  Cartography  and  Geographic  Information  Sci-ence 31(4), 237252 (2004) Fabrikant,  S.I.,  Montello,  D.R.,  Mark,  D.M.:  The  Distance-Similarity  Metaphor  in  Region-Display Spatializations. IEEE Computer Graphics & Application, 3444 (2006) Fabrikant,  S.I.,  Rebich-Hespanha,  S.,  Hegarty,  M.:  Cognitively  Adequate  and  Perceptually Salient Graphic Displays for Efficient Spatial Inference Making. Annals of the Association of American Geographers (in press) Goldberg, J.H., Kotval, X.P.: Computer Interface Evaluation using Eye Movements: Methods and Constructs. International Journal of Industrial Ergonomics 24, 631645 (1999) Goldstein, E.B.: Sensation & Perception, 2nd edn., Wadsworth, Belmont, CA (1989) Gregory,  R.L.  (ed.):  The  Oxford  Companion  to  the  Mind,  pp.  491493.  Oxford  University Press, Oxford Griffin,  A.L.:  Visual  Variables.  In:  Kemp,  K.  (ed.)  Encyclopedia  of  Geographic  Information Science, pp. 506509. SAGE Publication, Thousand Oaks (2008) Henderson,  J.M.,  Ferreira,  F.:  Scene  Perception  for  Psycholinguists.  In:  Henderson,  J.M., Ferreira, F. (eds.) The Integration of Language, Vision, and Action: Eye Movements and the Visual World, pp. 158. Psychology Press, New York (2004) Irwin,  E.:  Fixation  Location  and  Fixation  Duration  as  Indices  of  Cognitive  Processing.  In: Henderson, J.M., Ferreira, F. (eds.) The Integration of Language, Vision, and Action: Eye Movements and the Visual World, pp. 105134. Psychology Press, New York (2004) Itti,  L.,  Koch,  C.:  Computational  Modeling  of  Visual  Attention.  Nature  Reviews  Neurosci-ence 2(3), 194203 (2001) Itti,  L.,  Koch,  C.,  Niebur,  E.:  A  Model  of  Saliency-Based  Visual  Attention  for  Rapid  Scene Analysis.  IEEE  Transactions  on  Pattern  Analysis  and  Machine  Intelligence 20(11),  12541259 (1998) Jacob,  R.J.K.,  Karn,  K.S.:  Eye  Tracking  in  Human-computer  Interaction  and  Usability  Re-search:  Ready  to  Deliver  the  Promises.  In:  Hyn,  J.,  Radach,  R.,  Deubel,  H.  (eds.)  The Minds Eye: Cognitive and Applied Aspects of Eye Movement Research, pp. 573605. El-sevier, Amsterdam (2003) Koch, C.: Selective Visual Attention and Computational Models (2004),       http://www.klab.caltech.edu/cns186/PS/attention-koch.pdf Lloyd, R.: Visual Search Processes Used in Map Reading. Cartographica 34(1), 1112 (1997) Lloyd, R., Hodgson, M.E.: Visual Search for Land Use Objects in Aerial Photographs. Cartog-raphy and Geographic Information Science 29(1), 315 (2002) Lowe, R.K.: Animation and Learning: Selective Processing of Information in Dynamic Graph-ics. Learning and Instruction (13), 157176 (2003) \f",
      " Evaluating the Effectiveness and Efficiency of Visual Variables 211 MacEachren,  A.M.:  How  Maps  Work.  Representation,  Visualization,  and  Design.  Guilford Press, New York (1995) MacEachren,  A.M.,  Kraak,  M.-J.:  Research  Challenges  in  Geovisualization.  Cartography  and Geographic Information Science 28, 312 (2001) Morrison, J.L.: A Theoretical Framework For Cartographic Generalization with the Emphasis on  the  Process  of  Symbolization.  International  Yearbook  of  Cartography 14,  115127 (1974) Muller, J.C.: Bertins Theory of Graphics/A Challenge to North American Thematic Cartogra-phy. Cartographica 18(3), 18 (1981) Palsky, G.: The Debate on the Standardization of Statistical Maps and Diagrams (1857-1901). Elements  for  the  history  of  graphical  language.  Cybergeo:  European  Journal  of  Geogra-phy (85) (1999) (March 16, 1999),       http://www.cybergeo.eu/index148.html  Parkhurst, D., Law, K., Niebur, E.: Modeling the Role of Salience in the Allocation of Overt Visual Attention. Vision Research 42, 107123 (2002) Rensink,  R.A.,  ORegan,  J.K.,  Clark,  J.J.:  To  See  or  Not  to  See:  The  Need  for  Attention  to Perceive Changes in Scenes. Psychological Science 8, 368373 (1997) Rensink, R.A.: Change Detection. Annual Review of Psychology 53, 245277 (2002) Rensink,  R.A.:  Change  Blindness.  In:  Itti,  L.,  Rees,  G.,  Tsotsos,  J.K.  (eds.)  Neurobiology  of Attention, pp. 7681. Elsevier, San Diego (2005) Rosenholtz,  R.,  Li,  Y.,  Nakano,  L.:  Measuring  Visual  Clutter.  Journal  of  Vision 7(2),  122 (2007) Simons, D.J.: Current Approach to Change Blindness. Visual Cognition 7(1/2/3), 115 (2000) Slocum,  T.A.,  McMaster,  R.B.,  Kessler,  F.C.,  Howard,  H.H.:  Thematic  Cartography  &  Geo-graphic Visualization, 3rd edn. Prentice Hall, Upper Saddle River (2008) Swienty, O., Kurz, F., Reichenbacher, T.: Attention Guiding Visualization in Remote Sensing IIM Systems. Photogrammetrie, Fernerkundung, Geoinformation 4, 239251 (2007) Treisman,  A.M.,  Gelade,  G.:  Feature-Integration  Theory  of  Attention.  Cognitive  Psychol-ogy 12, 97136 (1980) Wolfe, J.M., Horowitz, T.S.: What Attributes Guide the Deployment of Visual Attention and how do they do it? Nature Reviews Neuroscience 5(6), 17 (2004) Wright, R.D., Ward, L.M.: Orienting of Attention. Oxford University Press, New York (2008) Yarbus, A.L.: Eye Movements and Vision. Plenum, New York (1967)  \f",
      "\n"
     ]
    }
   ],
   "source": [
    "print a.txt.loc[104]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
